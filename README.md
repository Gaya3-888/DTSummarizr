# DTSummarizr - Transcription & Summarization System

A robust AI-powered call center transcription and summarization system. This project transcribes audio calls, processes the text, and provides summaries using AI-powered natural language processing.

---

## Features

âœ… **Audio Transcription:** Convert call recordings into text using OpenAI Whisper.\
âœ… **Summarization:** Generate concise summaries using OpenAI GPT models.\
âœ… **Sentiment Analysis:** Detect the tone and sentiment of transcribed calls.\
âœ… **Multi-Language Support:** Process audio in multiple languages.\
âœ… **Database Storage:** Store transcriptions and summaries in MongoDB.\
âœ… **Secure API Access:** Authenticate users via JWT-based security.

---


## Tech Stack

| **Component**      | **Technology Used**                                             |
| ------------------ | --------------------------------------------------------------- |
| **Backend**        | Node.js, Express.js                                             |
| **Frontend**       | React                                                            |
| **Database**       | MongoDB (Mongoose)                                              |
| **File Storage**   | Multer, AWS S3                                                  |
| **Speech-to-Text** | OpenAI Whisper, Google Speech-to-Text, AWS Transcribe, Deepgram |
| **Summarization**  | OpenAI GPT                                                      |
| **NLP Processing** | spaCy, NLTK                                                     |
| **Authentication** | JWT, bcrypt                                                     |
| **API Testing**    | Postman
                                                     |

---


## Workflow

1ï¸âƒ£ User Uploads Audio â†’ Node.js API Stores File (uploads/ directory) â†’ Saves Metadata in MongoDB\
2ï¸âƒ£ Node.js Calls Python (transcribe.py) â†’ Python Transcribes Audio â†’ Stores in MongoDB (Status: "Completed")\
3ï¸âƒ£ Node.js Fetches Transcription â†’ Calls Python (summarize.py) â†’ Python Summarizes â†’ Saves to MongoDB\
4ï¸âƒ£ Node.js Fetches Summary â†’ Sends Summary to User via API

---

## Project Structure

```
ğŸ“¦ call-center-summarization
 â”£ ğŸ“‚ backend
 â”ƒ â”£ ğŸ“‚ config
 â”ƒ â”ƒ â”— ğŸ“œ db.js              		# MongoDB connection
 â”ƒ â”£ ğŸ“‚ controllers
 â”ƒ â”ƒ â”£ ğŸ“œ authController.js  		# Handles authentication (JWT)
 â”ƒ â”ƒ â”£ ğŸ“œ callController.js  		# Manages call records
 â”ƒ â”ƒ â”£ ğŸ“œ summaryController.js 		# Handles summarization logic
 â”ƒ â”ƒ â”£ ğŸ“œ transcriptionController.js 	# Handles transcriptions (JS version)
 â”ƒ â”ƒ â”£ ğŸ“œ youtubeController.js 		# Handles YouTube transcription (JS)
 â”ƒ â”ƒ â”£ ğŸ“œ videoController.js 		# Handles video-to-audio conversion (JS)
 â”ƒ â”ƒ â”— ğŸ“œ analyticsController.js 		# Sentiment & processing time tracking
 â”ƒ â”£ ğŸ“‚ middleware
 â”ƒ â”ƒ â”£ ğŸ“œ authMiddleware.js   	# JWT authentication
 â”ƒ â”ƒ â”£ ğŸ“œ errorHandler.js     	# Handles errors globally
 â”ƒ â”ƒ â”— ğŸ“œ timerMiddleware.js  	# Logs processing time for API requests
 â”ƒ â”£ ğŸ“‚ models
 â”ƒ â”ƒ â”£ ğŸ“œ Call.js             		# Call schema (audio file metadata)
 â”ƒ â”ƒ â”£ ğŸ“œ File.js             		# File metadata schema
 â”ƒ â”ƒ â”£ ğŸ“œ Settings.js         	# User settings schema
 â”ƒ â”ƒ â”£ ğŸ“œ Summary.js          	# Summarization schema
 â”ƒ â”ƒ â”£ ğŸ“œ Transcription.js    	# Transcription schema
 â”ƒ â”ƒ â”£ ğŸ“œ User.js             	# User schema
 â”ƒ â”ƒ â”— ğŸ“œ Video.js            	# Stores video metadata (file path, extracted audio)
 â”ƒ â”£ ğŸ“‚ routes
 â”ƒ â”ƒ â”£ ğŸ“œ calls.js            		# Routes for handling calls
 â”ƒ â”ƒ â”£ ğŸ“œ summaries.js        	# Routes for managing summaries
 â”ƒ â”ƒ â”£ ğŸ“œ transcriptions.js   	# Routes for transcriptions (JS)
 â”ƒ â”ƒ â”£ ğŸ“œ youtube.js          	# Routes for YouTube video transcription (JS)
 â”ƒ â”ƒ â”— ğŸ“œ video.js            	# Routes for video-to-audio conversion (JS)
 â”ƒ â”£ ğŸ“‚ utils
 â”ƒ â”ƒ â”£ ğŸ“œ fileHandler.js      	# Handles file uploads (Multer)
 â”ƒ â”ƒ â”£ ğŸ“œ summaryUtils.js     	# Summarization helper functions
 â”ƒ â”ƒ â”£ ğŸ“œ transcribeUtils.js  	# Transcription functions (Whisper JS)
 â”ƒ â”ƒ â”£ ğŸ“œ nlpUtils.js         	# NLP-based text processing
 â”ƒ â”ƒ â”£ ğŸ“œ youtubeUtils.js     	# Downloads & extracts audio from YouTube videos (JS)
 â”ƒ â”ƒ â”— ğŸ“œ videoUtils.js       	# Converts video files to audio (JS)
 â”ƒ â”£ ğŸ“‚ uploads
 â”ƒ â”ƒ â”£ ğŸ“‚ transcripts/        	# Stores generated transcription text files
 â”ƒ â”ƒ â”£ ğŸ“‚ audio/              	# Stores extracted audio from YouTube & video files
 â”ƒ â”ƒ â”£ ğŸ“‚ videos/             	# Stores uploaded video files before conversion
 â”ƒ â”ƒ â”£ ğŸ“œ sample_audio.mp3   	# Example audio file
 â”ƒ â”ƒ â”— ğŸ“œ sample_video.mp4   	# Example video file
 â”ƒ â”£ ğŸ“‚ python_scripts
 â”ƒ â”ƒ â”— ğŸ“œ full_transcription.py 	# Python-based transcription & summarization (YouTube, MP4, MP3)
 â”ƒ â”ƒ 
 â”ƒ â”£ ğŸ“œ server.js             		# Main Express server file (JS API)
 â”ƒ â”£ ğŸ“œ requirements.txt      	# Python dependencies for `full_transcription.py`
 â”ƒ â”£ ğŸ“œ run_transcription.py    	# Python script wrapper to execute `full_transcription.py`
 â”ƒ â”£ ğŸ“œ .gitignore            		# Ignore node_modules, .env, uploads
 â”ƒ â”£ ğŸ“œ .env                  		# Environment variables
 â”ƒ â”— ğŸ“œ package.json          	# Backend dependencies
 â”£ ğŸ“‚ frontend (TBD)
 â”— ğŸ“œ README.md                # Documentation
```

---

## Setup & Installation

### 1ï¸âƒ£ Clone the Repository

```sh
git clone https://github.com/Aacgectyuoki/call-center-summarization.git
cd call-center-summarization
```

### 2ï¸âƒ£ Install Backend Dependencies

```sh
cd backend
npm install
```

### 3ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in the `backend` folder:

```
MONGO_URI=your_mongodb_connection_string
JWT_SECRET=your_jwt_secret
OPENAI_API_KEY=your_openai_api_key
```

### 4ï¸âƒ£ Run the Backend Server

```sh
npm start
```

---

## ğŸ›‹ï¸ API Workflow

1ï¸âƒ£ **File Upload**

- User uploads an audio file (`.mp3`, `.wav`) via API.
- Technology: Multer (Node.js file handling).

2ï¸âƒ£ **Transcription Processing**

- Converts audio into text using OpenAI Whisper, AWS Transcribe, or Google Speech-to-Text.
- Stores transcription in MongoDB.

3ï¸âƒ£ **Summarization & Analysis**

- OpenAI GPT generates a summary.
- Sentiment analysis runs on the transcription.

4ï¸âƒ£ **API Response**

- The processed text and summary are sent to the user via API.

---

## API Endpoints

| Method | Endpoint                  | Description                  |
| ------ | ------------------------- | ---------------------------- |
| `POST` | `/api/auth/register`      | Register a new user          |
| `POST` | `/api/auth/login`         | Authenticate user (JWT)      |
| `POST` | `/api/calls`              | Upload a new call audio file |
| `GET`  | `/api/calls`              | Retrieve all call records    |
| `POST` | `/api/transcriptions`     | Transcribe an audio file     |
| `GET`  | `/api/transcriptions/:id` | Retrieve transcription by ID |
| `POST` | `/api/summaries`          | Summarize a transcription    |
| `GET`  | `/api/summaries/:id`      | Retrieve summary by ID       |

---

## Testing with Postman

1ï¸âƒ£ Start the backend server.\
2ï¸âƒ£ Open **Postman** and send a `POST` request to `/api/calls` with an audio file.\
3ï¸âƒ£ Wait for transcription and summarization to process.\
4ï¸âƒ£ Fetch the summary with a `GET` request to `/api/summaries/:id`.

---

## Contributing

Want to contribute? Open an issue or submit a pull request!

---

## Future Improvements

**Real-Time Transcription** (WebSockets for live call processing).\
**Multi-Language Support** (Translate transcriptions automatically).\
**Advanced Analytics** (Track call sentiment trends).

---

## License

MIT License Â© 2025 Max Dell-Thibodeau & Friends & Family

---

This README provides all the necessary details to set up, run, and test the project. Let me know if you want any refinements! ğŸš€

